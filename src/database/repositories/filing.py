# src/database/repositories/filing.py

import logging
from typing import List, Dict, Optional, Sequence, Set
from sqlalchemy import select, join, or_
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.dialects.mysql import insert as mysql_insert  # Import MySQL insert

from .base import AbstractRepository, SessionFactory
from src.database.models import Filing, Company
from src.database.session import get_session
from src.core.exceptions import DatabaseError, DatabaseQueryError
from src.config.settings import get_settings

from datetime import date

logger = logging.getLogger(__name__)


class FilingRepository(AbstractRepository):
    """
    Provides data access methods for Filing entities.
    Uses MySQL INSERT IGNORE for efficient bulk insertion, skipping duplicates.
    """

    def __init__(self, session_factory: SessionFactory):
        """
        Initializes the repository with a SQLAlchemy session factory.

        Args:
            session_factory: A callable (typically a scoped_session instance)
                             that returns a new Session object when called.
        """
        super().__init__(session_factory)  # Initialize the base class

    def get_by_accession_number(self,
                                accession_number: str) -> Optional[Filing]:
        """
        Retrieves a single Filing by its accession number.

        Args:
            accession_number: The accession number of the filing.

        Returns:
            The Filing object if found, otherwise None.

        Raises:
            DatabaseQueryError: If the database query fails.
        """
        logger.debug(
            f"Querying Filing by accession number: {accession_number}")
        with get_session(self.session_factory) as session:
            try:
                stmt = select(Filing).where(
                    Filing.accession_number == accession_number)
                result = session.execute(stmt)
                filing = result.scalar_one_or_none()
                logger.debug(
                    f"Filing query result for {accession_number}: {'Found' if filing else 'Not Found'}"
                )
                return filing
            except SQLAlchemyError as e:
                logger.error(
                    f"Database error querying filing by accession number {accession_number}: {e}",
                    exc_info=True)
                raise DatabaseQueryError(
                    f"Failed to query filing {accession_number}")

    def bulk_insert_ignore(self, filing_mappings: List[Dict]) -> int:
        """
        Efficiently inserts multiple new filings, ignoring any rows that would
        violate unique constraints (like on accession_number) using MySQL's
        INSERT IGNORE statement.

        Args:
            filing_mappings: A list of dictionaries, where each dictionary
                             represents a filing's data (must include keys matching
                             Filing model columns, especially 'accession_number', 'cik').

        Returns:
            The number of rows actually inserted (as reported by MySQL).

        Raises:
            DatabaseError: If the bulk operation fails for reasons other than
                           duplicate keys handled by IGNORE.
        """
        if not filing_mappings:
            logger.info(
                "bulk_insert_ignore called with empty list, no action taken.")
            return 0

        logger.info(
            f"Starting bulk insert ignore for {len(filing_mappings)} filing mappings."
        )

        # Optional: Add validation to ensure required keys (like accession_number, cik) exist?
        # For now, assume mappings are valid as generated by the parser/pipeline.
        # valid_mappings = [m for m in filing_mappings if 'accession_number' in m and 'cik' in m]
        # if len(valid_mappings) != len(filing_mappings):
        #     logger.warning(...)
        # if not valid_mappings: return 0
        # Use valid_mappings below if implementing validation.

        filing_table = Filing.__table__

        # Construct the INSERT IGNORE statement
        stmt = mysql_insert(filing_table).values(
            filing_mappings)  # Use original list for now
        stmt = stmt.prefix_with("IGNORE", dialect="mysql")

        affected_rows = 0
        with get_session(self.session_factory) as session:
            try:
                logger.info(
                    f"Executing bulk insert ignore statement for {len(filing_mappings)} potential filings..."
                )
                result = session.execute(stmt)
                # MySQL reports rows affected (only counts actual inserts, ignores skipped rows)
                affected_rows = result.rowcount
                logger.info(
                    f"Bulk insert ignore statement executed. Rows inserted: {affected_rows}"
                )
                # Commit happens automatically via get_session context manager

            except SQLAlchemyError as e:
                logger.error(
                    f"Database error during bulk insert ignore operation: {e}",
                    exc_info=True)
                # Rollback is handled automatically by get_session
                # This error would be something other than a duplicate key, e.g., connection issue, bad data type
                raise DatabaseError(f"Bulk insert ignore failed: {e}")
            except Exception as e:
                logger.error(
                    f"Unexpected error during bulk insert ignore: {e}",
                    exc_info=True)
                # Rollback handled automatically
                raise DatabaseError(
                    f"Unexpected error during bulk insert ignore: {e}")

        logger.info(
            f"Bulk insert ignore finished. Actual rows inserted: {affected_rows}."
        )
        return affected_rows

    def find_filings_for_download(self,
                                  form_types: Sequence[str],
                                  start_date: Optional[date] = None,
                                  end_date: Optional[date] = None,
                                  limit: Optional[int] = None) -> List[Dict]:
        """
        Finds filings matching criteria, excluding those from non-operating companies
        based on SIC codes defined in settings. Returns basic info needed for download prep.

        Args:
            form_types: Sequence of upper-case form types to include (e.g., ['10-K', '10-K/A']).
            start_date: Optional start date (inclusive) for filtering by filing_date.
            end_date: Optional end date (inclusive) for filtering by filing_date.
            limit: Optional maximum number of filings to return.

        Returns:
            A list of dictionaries, each containing 'cik' and 'accession_number'
            for the matching filings.

        Raises:
            DatabaseQueryError: If the database query fails.
        """
        # Fetch excluded SIC codes from settings
        settings = get_settings(
        )  # Needs to be called within method scope potentially
        excluded_sics = settings.filing_filter.excluded_sic_codes

        logger.info(f"Querying filings for download. Types: {form_types}, "
                    f"Excluding SICs: {excluded_sics}, "
                    f"Start: {start_date}, End: {end_date}, Limit: {limit}")

        # Construct the base query with the JOIN and essential columns
        stmt = select(
                 Filing.cik,
                 Filing.accession_number
                 # Add Filing.filing_date if needed for ordering before limit
                 # Filing.filing_date
               )\
               .select_from(join(Filing, Company, Filing.cik == Company.cik)) \
               .where(Filing.form_type.in_(form_types)) \
               .where(
                   or_( # Include if SIC is NULL or NOT IN the excluded list
                       Company.sic == None,
                       Company.sic.notin_(excluded_sics)
                   )
               )

        # Add optional date filters
        if start_date:
            stmt = stmt.where(Filing.filing_date >= start_date)
        if end_date:
            stmt = stmt.where(Filing.filing_date <= end_date)

        # Add ordering - important if using limit to get specific subset (e.g., latest)
        # Defaulting to most recent first if limit is applied
        if limit:
            stmt = stmt.order_by(Filing.filing_date.desc(), Filing.id.desc())
            stmt = stmt.limit(limit)
        else:
            # Default ordering if no limit (can be adjusted)
            stmt = stmt.order_by(Filing.filing_date.asc(), Filing.cik.asc(),
                                 Filing.id.asc())

        results_list = []
        with get_session(self.session_factory) as session:
            try:
                results = session.execute(stmt)
                # Convert results to list of dictionaries using RowMapping._asdict()
                results_list = [dict(row) for row in results.mappings()]
                logger.info(
                    f"Found {len(results_list)} filings matching download criteria after filtering."
                )
            except SQLAlchemyError as e:
                logger.error(
                    f"Database error finding filings for download: {e}",
                    exc_info=True)
                raise DatabaseQueryError(
                    "Failed to query filings for download")

        return results_list

    # Add other methods as needed, e.g., find_filings_by_cik, find_filings_by_form_and_date etc.
